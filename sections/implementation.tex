% TODO This chapter *must* detail our implementation of the modules introduced in System Design!

With the background of the high-level foundations presented in chapter\ref{chap:design}, this chapter details the underlying implementation of the modules of the whole system. All source code has been written in JavaScript. \texttt{DHT} is run as a Node.js server and \texttt{Shuttle} runs as a web application. Rymd is the platform independent core module containing the business logic of the system. All other modules contain the specific implementations for each problem area (see figure~\ref{fig:architecture}).

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth,height=0.4\paperheight,keepaspectratio
]{figures/architecture}
\caption{The modules and external APIs utilized in Rymd and Shuttle}
\label{fig:architecture}
\end{figure}

\section{Rymd}
\label{sec:rymd}

% TODO Somebody

The source code is available at: https://github.com/rymdjs/rymd. The Rymd library is the only truly implementation-agnostic module and should be runnable on any platform as long as implementation modules are dependency injected. 

\section{Shuttle}
\label{sec:shuttle}
The front-end prototype was built in order to test and implement the features of Rymd. Early versions included a minimum viable interface for adding, showing and sending files. This was further iterated over, ending up letting the user:

\begin{itemize}
  \item Add files through form control or drag-and-drop
  \item Share, view and delete files
  \item Login (verifies with the DHT, see~\ref{sec:authentication})
  \item Get in-app notifications for incoming sharing requests
  \item Download remote files that have been shared by other users
  \item Add custom encryption keys
\end{itemize}

The source code is available at: https://github.com/rymdjs/prototype.

Shuttle uses Rymd's functionality by instantiating a global \texttt{RymdNode} object (see~\ref{sec:rymd}). This effectively makes Shuttle a node in the network. In-app notifications are shown by listening to certain events on the \texttt{rymdNode} object.

When the front-end Javascript code was beginning to grow fairly complex, a decision was made to rewrite the code for the front-end framework Backbone\footnote{http://backbonejs.org}. Backbone provides a barebones concept of models, collections, views and events, as well as a URL router. The prototype was thus restructured and integrated with Backbone's patterns.

\subsection{Persisting front-end models}

A major feature of Backbone is the ability to connect to an existing data API for persisting front-end models to a backend. By the use of \texttt{XMLHttpRequest} for asynchronous HTTP requests, Backbone is able to talk to a RESTful API when creating, reading, updating or deleting models. However, in Shuttle the data should not be persisted to a remote server, but instead use the local data store in Rymd (see~\ref{sec:indexeddbstore}). A custom adapter was written\footnote{https://github.com/rymdjs/prototype/blob/develop/lib/Backbone.ResourceStore.js}, which intercepts Backbone's calls by overriding the \texttt{sync} method to make it communicate with the local store with CRUD actions.

\begin{Code}
\begin{lstlisting}[caption={Sample scenario of persisting models}, label={lst:backbonesync}]

// The custom overriden adapter for persisting to a local store
var ResourceStore = require("../Backbone.ResourceStore");

// Define a new collection using the adapter above
var ResourcesCollection = Backbone.Collection.extend({
  model: File,

  initialize: function() {
    // Inject App.rymdNode.store, which is an instance of the IndexedDBStore module
    this.resourceStore = new ResourceStore(App.rymdNode.store);
  }
});

// Backbone Collection for in-memory storage of models
var myFiles = new ResourcesCollection();

// Populate the collection with file models from the local store
myFiles.fetch();

// Create a file model for the collection. The model is now automatically saved to the local store,
// thanks to the above mentioned adapter.
myFiles.create(new File());
\end{lstlisting}
\end{Code}

\section{Authentication (DHT, DHT Client)}
\label{sec:authentication}
Since the default authentication implementation utilizes Namecoin, which can not be accessed directly from a web application, a gateway service needs to be used. Therefore, the domain of authentication spans over several parts in separate systems:

\begin{description}
  \item[DHT] A NodeJS\footnote{http://nodejs.org} based server that looks up entries in the Namecoin blockchain. It is also used to keep track of session-based IDs, as described under~\ref{sec:communication}. This is the only module that runs outside of the Rymd library.
  \item[DHT-Client] Client-side interface module to the DHT.
  \item[ConnectionHandler] Submodule in the Rymd library. Implements the Needham-Schroeder-Lowe authentication business logic.
\end{description}

The idea with this separation is that the authentication algorithm is part of the core library, while derivative projects should be able to replace $DHT$ and $DHT-client$ with implementations using other stores like Ethereum or Keybase without having to consider writing a secure authentication protocol, should they so desire.

The source code is available at: https://github.com/rymdjs/dht-client and https://github.com/rymdjs/dht.

\section{Cryptography}
\label{sec:cryptography}
%TODO: Rewrite, explain "secure primitives". Probably this whole sentence should be removed./Robert
% uses the Web Crypto Api for encryption (3AES - 1024) ,decryption key import and export ,
The implementations of WebCrypto in Chromium supply key generation, but there is no support for persisting keys between sessions or even exporting private keys. W3C - the organization behind WebCrypto - have announced their intention to handle persistent key storage in an upcoming API called WebCrypto Key Discovery \cite{WebCryptoKeyDiscovery:Online}. However, Google has no intention of implementing this in Chromium before the WebCrypto API is finalized. WebCrypto Key Discovery API was originally intended to be a part of the WebCrypto API but was extracted in order to decrease implementation complexity.

\subsection{Algorithms}
RymdCrypto uses two algorithms for encryption, namely $RSAES-PKCS1-v1.5$ and $AES-CBC$. AES-CBC is a fast and simple to use symmetric key algorithm based on AES using cipher block chaining\cite{AESISFAST:Online}. Rymd's signing algorithm uses $RSAES-PKCS1-v1.5$ mainly because it is recommended by the working group behind the WebCrypto API. This choice is further motivated by the lack of alternatives: There are no other RSA algorithms intended for signing included in the WebCrypto API.

Also, a good hashing algorithm is needed in order to avoid collision of hashes, in other words to avoid having two generated hash values being exactly the same (similar to the \emph{birthday problem}~\footnote{http://statistics.about.com/od/ProbHelpandTutorials/a/What-Is-The-Birthday-Problem.htm}). For hashing purposes RymdCrypto uses SHA-256 as explained in section~\ref{sec:creationofresources}.

RSA is currently the only asymmetric encryption scheme supported in WebCrypto. There are two encryption algorithms to choose from: $RSAES-PKCS1-v1.5$ and $RSA-OAEP$. $RSAES-PKCS1-v1.5$ can use the same keys for encryption and signing, which makes it the natural choice for Rymd. See table~\ref{table:webcryptoapi}. 

%Cryptoback.js
% \begin{Code}
% \begin{lstlisting}[caption={Included database operations}, label={lst:cryptoback}]
%  //dependecies cryptoback.js
%   var rsa = require('bignumber-jt'),
%       Q = require('q');

%  //dependecies crypto.js
%   var root = this,
%     Q = require('q'),
%     cryptojs = require('crypto-js'),
%     utils = require("./cryptoback");
% \end{lstlisting}
% \end{Code}

% add text about hashing
% why is the hashing in
\begin{table}[ht]
\centering
\begin{tabular}{lcccccc}
Algorithm name & Type & Encrypt & Decrypt & Sign & Verify & ImportKey \\
RSAES-PKCS1-v1\_5 & ASYM & x & x &  &  & x \\
RSASSA-PKCS1-v1\_5 & ASYM &  &  & x & x & x \\
RSA-PSS & ASYM &  &  & x & x & x \\
RSA-OAEP & ASYM & x & x &  &  & x \\
ECDSA & ASYM &  &  & x & x & x \\
AES-CTR & SYM & x & x &  &  & x \\
AES-CBC & SYM & x & x &  &  & x \\
AES-CMAC & SYM &  &  & x & x & x \\
AES-GCM & SYM & x & x &  &  & x \\
AES-CFB & SYM & x & x &  &  & x
\end{tabular}
\caption{Some WebCrypto API algorithms}
\label{table:webcryptoapi}
\end{table}

Commercial RSA certificates are more widely deployed compared to DSA certificates. Furthermore, the asymmetric keys are wrapped in PKCS\#8 and SPKI certificates while the symmetric key exist in raw format. \emph{The Private-Key Information Syntax Standard} (PKCS\#8) defines a way to store the private key, and the \emph{Simple Public Key Infrastructure} (SPKI) defines a way to store the public key. All three standards was chosen because they are the only three formats that is currently supported by Chromium \cite{ImplementedChromium:Online}. See listing~\ref{lst:cryptoalgorithms} for a complete rundown of Rymd's algorithms.

\begin{Code}
\begin{lstlisting}[caption={Algorithms implemented}, label={lst:cryptoalgorithms}]
  var generationAlgorithmSign =  {
    name: "RSASSA-PKCS1-v1_5",
    modulusLength: 2048,
    publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
    hash: {
      name: "SHA-256"
    }
  },

  generationAlgorithmEncrypt =  {
    name: "RSAES-PKCS1-v1_5",
    modulusLength: 2048,
    publicExponent: new Uint8Array([0x01, 0x00, 0x01])
  },

  aesAlgorithmKeyGen = {
    name: "AES-CBC",
    length: 256
  },

 specFormats ={
    public: 'spki',
    private: 'pkcs8',
    secret: 'raw'
  }
\end{lstlisting}
\end{Code}

\subsection{Libraries}
Until the WebCrypto Key Discovery API is available, the RymdCrypto module generates pseudo-random keys through the external library \emph{bignumber-jt}\footnote{https://www.npmjs.org/package/bignumber-jt}. To do low-level key generation directly in JavaScript is bad practice and is performed in order to make Rymd runnable until a more solid solution is available.

Furthermore, IndexedDB is used as makeshift storage since the WebCrypto API lacks functionality for storing keys between sessions, or even exporting private keys. In order to use IndexedDB for the keys they need to be parsed to certificates. This is also handled by bignumber-jt. All certificates have a static key size where asymmetric keys are of $1024bits$ and symmetric keys are of $256bits$; none are explicitly generated via the API.

Hashing is handled by the external library \emph{crypto-js}\footnote{https://github.com/evanvosberg/crypto-js}.

\subsection{Interface}
before it's imported into its low-level interface. %TODO: Proper reference
\begin{Code}
\begin{lstlisting}[caption={Common database operations}, label={lst:cryptointerface}]
generateKeyPair: function() -> Promise({Uint8array,Uint8array})
exportKey: function(WebCrypto::Key) -> Promise({Uint8array})
importKey: function(String,Uint8array) -> Promise(WebCrypto::Key)
signKey: function(WebCrypto::Key,Uint8Array) -> Promise
verifyKey: function(WebCrypto::Key,Uint8Array,Uint8Array) -> Promise
encrypt**: function(WebCrypto::Key,Uint8Array??) -> Promise(Arraybuffer)
decrypt**: function(WebCrypto::Key,Uint8Array??) -> Promise(Arraybuffer)
hash**: function(blob)  -> Promise(blob)
generateSymmetricKey: function() -> Promise(WebCrypto::Key)
\end{lstlisting}
\end{Code}

The source code is available at: https://github.com/rymdjs/crypto.

\section{IndexedDBStore}
\label{sec:indexeddbstore}

The main task for the data storage module was to abstract away the low-level methods in IndexedDB (the backing store used, see section~\ref{sec:indexeddb}). An API example can be found in listing~\ref{lst:indexeddbapi}. The module supports use of multiple object stores and auto-generation of GUID keys.

The source code is available at: https://github.com/rymdjs/data-storage.

\begin{Code}
\begin{lstlisting}[caption={Common database operations}, label={lst:indexeddbapi}]
var IndexedDbStore = require("indexeddbstore")

var Store = new IndexedDbStore("myStore")

// Fetch all records as an array
Store.all().then(function(records) { ... })

// Create a record
Store.create("A record").then(function(record){ ... })

// Insert a record
Store.save("A record").then(function(guid){ ... })

// Fetch a record by GUID
Store.get(guid).then(function(record) { ... })

// Delete a record by GUID
Store.destroy(guid).then(function(record) { ... })
\end{lstlisting}
\end{Code}

The largest challenge came to the edge cases when storing files, or as they are called in web browser: \emph{Blobs}. Since at present only Firefox can store blobs directly in IndexedDB, an alternate route had to be taken for other browsers. Initially the module used conditionals and converted incoming data to and from \emph{ArrayBuffers} (the browser construct for raw byte streams). But since ArrayBuffers are just the raw data, all metadata for the blobs (such as filename, timestamps, size) would be lost when saving as an ArrayBuffer. In early versions of the data storage module this metadata would be stored in a separate store in the database, but this was too tightly coupled and was removed. The final implementation is storing data as-is â€“ any metadata must be saved explicitly in a separate operation.

The asynchronous API of IndexedDB is relatively verbose and complex. It makes heavy use of event driven programming and thus the developer communicates with the database with callbacks. By the use of \emph{Promises}\footnote{http://en.wikipedia.org/wiki/Promise\_(programming)}, the asynchronous, callback-based methods in the IndexedDB API was made streamlined and simple to manage.

\section{PeerJS Connection}
\label{sec:p2p}

% - built on top of peerjs, TODO (not sure how to reference to github)
Rymd leverages the open source project PeerJS\footnote{http://peerjs.com}, which simplifies sending peer-to-peer data between clients. This module was therefore constructed, in line with the project guidelines regarding modularity, to contain PeerJS-specific code and to provide an independent interface which does not reveal the details of PeerJS's inner workings. If changes in Rymd's requirements makes the choice of PeerJS obsolete, then the changes will be isolated and one should still be able to depend on the same interface. 

PeerJS utilizes WebRTC and is essentially split into two components: a server which acts as the signaling channel, and a client side API which interacts with the server as well as other peers. The server only handles the brokering of connections, which implies that only the data necessary for negotiating a connection is sent through this point. For communication between the server and the clients, that is the signaling protocol, PeerJS utilizes both WebSockets and XMLHttpRequest \cite{PeerjsGithub:2014:Online}. After a connection has been setup between two clients, the server is no longer needed in order for them to communicate.

The source code is available at: https://github.com/rymdjs/peerjs-connection.

% - explain how peer.js works.
The following steps explain how PeerJS brokers connections:
\begin{enumerate}
\item Two clients connect to the PeerJS server, using the client side API.
\item The server returns unique IDs for each of the clients.
\item One of the clients connects to the other using the client side API, where the unique ID for the other one is provided. The PeerJS server then forwards the information needed to set up a peer-to-peer connection to the other client.
\end{enumerate}

In order to map the identity registered in the Namecoin blockchain to the ID supplied by the PeerJS server, the DHT service is used. After a client has connected to a PeerJS server, it supplies the data regarding the server IP and the generated ID to the DHT. When another client wants to create a peer-to-peer connection, it queries the DHT service for the Namecoin identity, which then returns the IP for the PeerJS server and the id for the client.

% TODO need to expand this
As communication with the PeerJS server and the DHT service utilize XHR and WebSockets, which is not encrypted per default, it is vital that these channels are encrypted to ensure the integrity of users.

\section{Testing}
\label{sec:testing}

Automatic unit tests have been implemented where possible. Thanks to the use of isolated modules test suites were able to be short and concise. Mocha was used as test runner, with Chai as assertion library (please see section~\ref{chap:libraries} for links to external libraries used).

\begin{Code}
\begin{lstlisting}[caption={Sample test suite}, label={lst:testsuite}]
describe("IndexedDBStore", function() {

  var db;

  beforeEach(function() {
		db = new IndexedDBStore({
			dbName: "test"
		});
	});

  it("should have a database name", function() {
		db.name.should.equal("test");
	});

  it("should save a record and return an id", function() {
		return db.save({foo: "bar"})
		.then(function(id) {
			id.should.be.a("String");
		});
	});

  it("should retrieve a given record", function() {
		return db.save({foo: "bar"})
      .then(db.get.bind(db))
      .then(function(record) {

			record.should.be.an("Object");
			record.data.foo.should.equal("bar");
		});
	});
});
\end{lstlisting}
\end{Code}

No integration or functional tests have been written for testing larger parts of the system. This is due to the fast iteration of the library's interface and constant change in implementation.
